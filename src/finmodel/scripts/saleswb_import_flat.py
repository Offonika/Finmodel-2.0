import json
import sqlite3
import time
from pathlib import Path

import requests
from requests.adapters import HTTPAdapter, Retry

from finmodel.logger import get_logger
from finmodel.utils.settings import (
    find_setting,
    load_organizations,
    load_period,
    parse_date,
)

logger = get_logger(__name__)


def main() -> None:
    # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä —Å—Ç—Ä–∞–Ω–∏—Ü—ã, –∑–∞—è–≤–ª–µ–Ω–Ω—ã–π –≤ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏ WB API
    PAGE_LIMIT = 100_000
    REQUEST_TIMEOUT = 60

    # --- Paths ---
    base_dir = Path(__file__).resolve().parents[3]
    db_path = base_dir / "finmodel.db"

    # --- –ü–æ–ª—É—á–∞–µ–º –ø–µ—Ä–∏–æ–¥ –∑–∞–≥—Ä—É–∑–∫–∏ ---
    period_start_raw, period_end_raw = load_period()
    if not period_start_raw or not period_end_raw:
        logger.error("Settings do not include –ü–µ—Ä–∏–æ–¥–ù–∞—á–∞–ª–æ/–ü–µ—Ä–∏–æ–¥–ö–æ–Ω–µ—Ü.")
        raise SystemExit(1)
    period_start = parse_date(period_start_raw).strftime("%Y-%m-%dT%H:%M:%S")
    period_end = parse_date(period_end_raw).strftime("%Y-%m-%dT%H:%M:%S")
    logger.info("–ü–µ—Ä–∏–æ–¥ –∑–∞–≥—Ä—É–∑–∫–∏ –ø—Ä–æ–¥–∞–∂: %s .. %s", period_start, period_end)

    # --- Load organizations ---
    sheet = find_setting("ORG_SHEET", default="–ù–∞—Å—Ç—Ä–æ–π–∫–∏")
    logger.info("Using organizations sheet: %s", sheet)
    df_orgs = load_organizations(sheet=sheet)
    if df_orgs.empty:
        logger.error("–ù–∞—Å—Ç—Ä–æ–π–∫–∏.xlsm –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–π —Å —Ç–æ–∫–µ–Ω–∞–º–∏.")
        raise SystemExit(1)

    # --- –í—Å–µ –≤–æ–∑–º–æ–∂–Ω—ã–µ –ø–æ–ª—è –ø—Ä–æ–¥–∞–∂–∏ (WB-API) ---
    SALES_FIELDS = [
        "date",
        "lastChangeDate",
        "warehouseName",
        "warehouseType",
        "countryName",
        "oblastOkrugName",
        "regionName",
        "supplierArticle",
        "nmId",
        "barcode",
        "category",
        "subject",
        "brand",
        "techSize",
        "incomeID",
        "isSupply",
        "isRealization",
        "totalPrice",
        "discountPercent",
        "spp",
        "paymentSaleAmount",
        "forPay",
        "finishedPrice",
        "priceWithDisc",
        "saleID",
        "sticker",
        "gNumber",
        "srid",
    ]

    # --- –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ –±–∞–∑–µ –∏ —Å–æ–∑–¥–∞–Ω–∏–µ –ø–ª–æ—Å–∫–æ–π —Ç–∞–±–ª–∏—Ü—ã ---
    conn = sqlite3.connect(db_path)
    cursor = conn.cursor()
    fields_sql = ", ".join([f"{f} TEXT" for f in SALES_FIELDS])
    cursor.execute("DROP TABLE IF EXISTS SalesWBFlat;")
    cursor.execute(
        f"""
    CREATE TABLE SalesWBFlat (
        org_id INTEGER,
        –û—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏—è TEXT,
        {fields_sql},
        PRIMARY KEY (org_id, srid)
    );
    """
    )
    conn.commit()

    # --- HTTP session ---
    def make_http() -> requests.Session:
        s = requests.Session()
        retries = Retry(
            total=5,
            read=5,
            connect=5,
            backoff_factor=0.5,
            status_forcelist=(429, 500, 502, 503, 504),
            allowed_methods=frozenset(["GET"]),
        )
        s.mount("https://", HTTPAdapter(max_retries=retries))
        s.mount("http://", HTTPAdapter(max_retries=retries))
        return s

    # --- API –∑–∞–ø—Ä–æ—Å ---
    url = "https://statistics-api.wildberries.ru/api/v1/supplier/sales"
    headers_template = {"Content-Type": "application/json"}

    http = make_http()

    for _, row in df_orgs.iterrows():
        org_id = row["id"]
        org_name = row["–û—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏—è"]
        token = row["Token_WB"]
        logger.info("‚Üí –û—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏—è: %s (ID=%s)", org_name, org_id)

        headers = headers_template.copy()
        headers["Authorization"] = token

        date_from = period_start
        total_loaded = 0
        page = 1

        while True:
            params = {"dateFrom": date_from}
            logger.info("  üì§ –ó–∞–ø—Ä–æ—Å page %s, dateFrom=%s ...", page, date_from)
            try:
                resp = http.get(url, params=params, headers=headers, timeout=REQUEST_TIMEOUT)
                if resp.status_code != 200:
                    logger.warning("  –ó–∞–ø—Ä–æ—Å –≤–µ—Ä–Ω—É–ª —Å—Ç–∞—Ç—É—Å %s: %s", resp.status_code, resp.text)
                    time.sleep(5)
                    break
                data = resp.json()
            except Exception as e:
                logger.warning("  –û—à–∏–±–∫–∞ –∑–∞–ø—Ä–æ—Å–∞: %s", e)
                time.sleep(5)
                break

            if not data:
                logger.info("‚úÖ –í—Å–µ –ø—Ä–æ–¥–∞–∂–∏ –∑–∞–≥—Ä—É–∂–µ–Ω—ã –¥–ª—è —ç—Ç–æ–π –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–∏.")
                break

            # –†–∞—Å–ø–∞–∫–æ–≤–∫–∞
            rows = []
            for rec in data:
                flat = [org_id, org_name] + [str(rec.get(f, "")) for f in SALES_FIELDS]
                rows.append(flat)
            try:
                placeholders = ",".join(["?"] * (2 + len(SALES_FIELDS)))
                cursor.executemany(
                    f"""
                    INSERT OR REPLACE INTO SalesWBFlat
                    VALUES ({placeholders})
                """,
                    rows,
                )
                conn.commit()
            except Exception as e:
                logger.warning("  –û—à–∏–±–∫–∞ –≤—Å—Ç–∞–≤–∫–∏: %s", e)
                break

            total_loaded += len(rows)
            logger.info("  +%s –ø—Ä–æ–¥–∞–∂ (–∏—Ç–æ–≥–æ: %s)", len(rows), total_loaded)

            if len(rows) < PAGE_LIMIT:
                logger.info("  ‚úÖ –ü—Ä–æ–¥–∞–∂–∏ –ø–æ –ø–µ—Ä–∏–æ–¥—É –∑–∞–≥—Ä—É–∂–µ–Ω—ã –ø–æ–ª–Ω–æ—Å—Ç—å—é.")
                break

            # pagination: —Å–ª–µ–¥—É—é—â–∏–π dateFrom = lastChangeDate –ø–æ—Å–ª–µ–¥–Ω–µ–π —Å—Ç—Ä–æ–∫–∏
            date_from = data[-1].get("lastChangeDate")
            page += 1
            time.sleep(3)  # WB –ª–∏–º–∏—Ç: 1 –∑–∞–ø—Ä–æ—Å –≤ –º–∏–Ω—É—Ç—É, –Ω–æ –º–æ–∂–Ω–æ —á—É—Ç—å —á–∞—â–µ

    conn.close()
    logger.info("‚úÖ –í—Å–µ –ø—Ä–æ–¥–∞–∂–∏ –∑–∞–≥—Ä—É–∂–µ–Ω—ã –∏ —Ä–∞—Å–ø–∞—Ä—Å–µ–Ω—ã –≤ —Ç–∞–±–ª–∏—Ü—É SalesWBFlat (–±–µ–∑ –¥—É–±–ª–µ–π).")


if __name__ == "__main__":
    main()
